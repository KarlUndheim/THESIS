{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier, DMatrix\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt import STATUS_OK\n",
    "from hyperopt import fmin, tpe, Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_BINEXP.csv')\n",
    "val = pd.read_csv('val_BINEXP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['species'] = train['species'].apply(lambda x: x if x in [1,2] else 3)\n",
    "val['species'] = val['species'].apply(lambda x: x if x in [1,2] else 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the label columns for later use\n",
    "train_labels = train['label']\n",
    "val_labels = val['label']\n",
    "\n",
    "# remove area codes and labels from data\n",
    "train = train.drop(['area_code', 'label'], axis=1)\n",
    "val = val.drop(['area_code', 'label'], axis=1)\n",
    "\n",
    "X_train = train.drop('species', axis=1)\n",
    "y_train = train['species']\n",
    "y_train = y_train-1\n",
    "\n",
    "X_val = val.drop('species', axis=1)\n",
    "y_val = val['species']\n",
    "y_val = y_val-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HELPER FUNCTION FOR FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_used_feats_names(feats_frame_columns, features_list):\n",
    "    \"\"\"\n",
    "    not all features saved in the features.csv will be used.\n",
    "    so we need to select which features are used.\n",
    "    :param feats_frame_columns: all feaetures' names\n",
    "                example [hrange, hmax, imax_0, imin_0, ..., imax_1,..., isk_2, ikut_2, ip90_2]\n",
    "                \"h\" or \"i\": feature's name.\n",
    "                    h: height, i:intensity\n",
    "    :param features_list: the features' list which will be considered.\n",
    "                example [h, i_max_min_sk]\n",
    "                the format of \"i_max_min_sk\" means that only max, min, sk subfeatures for intensity will be used.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    feats_names = feats_frame_columns  # np.arr, dtype=object\n",
    "    used_feats_bool = []\n",
    "\n",
    "    for f_considered in features_list:\n",
    "        if \"_\" in f_considered:\n",
    "            f_i_subattrs = np.zeros(shape=len(feats_names)).astype(\"bool\")\n",
    "            f_name = f_considered.split(\"_\")[0]   # feature type info. e.g. \"h\"(height), \"i\"(intensity)\n",
    "            f_i_sub = f_considered.split(\"_\")[1:] # feature sub info. e.g. \"max\", \"min\"\n",
    "            f_i_sub_channels = list(filter(lambda _:_ in [\"ch0\", \"ch1\", \"ch2\", \"ch3\"], f_i_sub)) # channel info: e.g.: \"ch1\"\n",
    "            for fi, fn in enumerate(feats_names): # fn e.g.: \"imax_1\", \"imin_1\"\n",
    "                if fn[0]==f_name: # judge h or i\n",
    "                    for s in f_i_sub: # s e.g. \"max\", \"min\", \"ch1\"\n",
    "                        if str(s) in fn or s.replace(\"ch\", \"\")==fn.split(\"_\")[-1]: # e.g.: \"max\" in \"imax_1\" and ch\"1\"==imax_\"1\"\n",
    "                            if len(f_i_sub_channels)==0: # no channel info. so this feature will be considered without the channel filter\n",
    "                                f_i_subattrs[fi] = True\n",
    "                            elif \"ch\"+str(fn)[-1] in f_i_sub_channels: # filter the feature info by channel.\n",
    "                                f_i_subattrs[fi] = True\n",
    "            used_feats_bool.append(f_i_subattrs)\n",
    "        else:\n",
    "            used_feats_bool.append([_[0] == f_considered for _ in feats_names])\n",
    "\n",
    "    used_feats_bool = np.sum(used_feats_bool, axis=0, dtype=bool)  # 1-d list, all columns name which will be considered\n",
    "    used_feats_names= feats_names[used_feats_bool]\n",
    "\n",
    "    if 'D_1' in features_list and 'D_10' not in features_list:\n",
    "        used_feats_names = used_feats_names[used_feats_names != 'D10']\n",
    "\n",
    "\n",
    "    return used_feats_names\n",
    "\n",
    "feats_cols = np.array(['hrange', 'hmax', 'hstd', 'hmean' ,'imax_0', 'imin_0', 'imean_0', 'isk_0', 'ikut_0', 'ip90_0',\n",
    " 'imax_1', 'imin_1', 'imean_1', 'isk_1', 'ikut_1', 'ip90_1', 'imax_2', 'imin_2',\n",
    " 'imean_2', 'isk_2', 'ikut_2', 'ip90_2','Rmin_0', 'Rmin_1', 'Rmin_2','Rp90_0', 'Rp90_1', 'Rp90_2', 'D1','D2','D3','D4','D5','D6','D7','D8','D9','D10', 'penetration',\n",
    " 'Rmean_0', 'Rmean_1', 'Rmean_2', 'Rmax_0', 'Rmax_1', 'Rmax_2', 'Rkut_0', 'Rkut_1', 'Rkut_2', 'Rsk_0', 'Rsk_1', 'Rsk_2', \n",
    " 'V_min', 'V_mean', 'V_max', 'V_median', 'V_std', 'V_sk', 'V_kut', 'V_p90', 'V_points',\n",
    "\n",
    "\n",
    " 'istd_0', 'irange_0', 'ip5_0', 'ip10_0', 'ip20_0', 'ip30_0', 'ip40_0', 'ipmedian_0', 'ip60_0', 'ip70_0', 'ip80_0',\n",
    " 'istd_1', 'irange_1', 'ip5_1', 'ip10_1', 'ip20_1', 'ip30_1', 'ip40_1', 'ipmedian_1', 'ip60_1', 'ip70_1', 'ip80_1',\n",
    " 'istd_2', 'irange_2', 'ip5_2', 'ip10_2', 'ip20_2', 'ip30_2', 'ip40_2', 'ipmedian_2', 'ip60_2', 'ip70_2', 'ip80_2',\n",
    " 'Rstd_0', 'Rrange_0', 'Rp5_0', 'Rp10_0', 'Rp20_0', 'Rp30_0', 'Rp40_0', 'Rpmedian_0', 'Rp60_0', 'Rp70_0', 'Rp80_0',\n",
    " 'Rstd_1', 'Rrange_1', 'Rp5_1', 'Rp10_1', 'Rp20_1', 'Rp30_1', 'Rp40_1', 'Rpmedian_1', 'Rp60_1', 'Rp70_1', 'Rp80_1',\n",
    " 'Rstd_2', 'Rrange_2', 'Rp5_2', 'Rp10_2', 'Rp20_2', 'Rp30_2', 'Rp40_2', 'Rpmedian_2', 'Rp60_2', 'Rp70_2', 'Rp80_2',\n",
    " 'Nstd', 'Nrange', 'Np5', 'Np10', 'Np20', 'Np30', 'Np40', 'Npmedian', 'Np60', 'Np70', 'Np80',\n",
    " 'Nmax', 'Nmin', 'Nmean', 'Nsk', 'Nkut', 'Np90',\n",
    " 'Amax', 'Amin', 'Amean', 'Ask', 'Akut', 'Ap90', 'Astd', 'Arange', 'Ap5','Ap10','Ap20','Ap30','Ap40','Apmedian','Ap60','Ap70','Ap80',\n",
    " 'Xmax', 'Xmin', 'Xmean', 'Xsk', 'Xkut', 'Xp90', 'Xstd', 'Xrange', 'Xp5','Xp10','Xp20','Xp30','Xp40','Xpmedian','Xp60','Xp70','Xp80',\n",
    " 'CA', 'CV', 'CD', 'HP10', 'HP20','HP30','HP40','HP50','HP60','HP70','HP80','HP90',\n",
    "\n",
    "'2binm1_0', '2binx1_0','2binm2_0','2binx2_0',\n",
    "'2binm1_1', '2binx1_1','2binm2_1','2binx2_1',\n",
    "'2binm1_2', '2binx1_2','2binm2_2','2binx2_2',\n",
    "\n",
    "'3binm1_0','3binx1_0', '3binm2_0','3binx2_0', '3binm3_0','3binx3_0',\n",
    "'3binm1_1','3binx1_1', '3binm2_1','3binx2_1', '3binm3_1','3binx3_1',\n",
    "'3binm1_2','3binx1_2', '3binm2_2','3binx2_2', '3binm3_2','3binx3_2',\n",
    "\n",
    "'4binm1_0','4binx1_0', '4binm2_0','4binx2_0', '4binm3_0','4binx3_0', '4binm4_0','4binx4_0',\n",
    "'4binm1_1','4binx1_1', '4binm2_1','4binx2_1', '4binm3_1','4binx3_1', '4binm4_1','4binx4_1',\n",
    "'4binm1_2','4binx1_2', '4binm2_2','4binx2_2', '4binm3_2','4binx3_2', '4binm4_2','4binx4_2',\n",
    "\n",
    "'5binm1_0','5binx1_0', '5binm2_0','5binx2_0', '5binm3_0','5binx3_0', '5binm4_0','5binx4_0', '5binm5_0','5binx5_0',\n",
    "'5binm1_1','5binx1_1', '5binm2_1','5binx2_1', '5binm3_1','5binx3_1', '5binm4_1','5binx4_1', '5binm5_1','5binx5_1',\n",
    "'5binm1_2','5binx1_2', '5binm2_2','5binx2_2', '5binm3_2','5binx3_2', '5binm4_2','5binx4_2', '5binm5_2','5binx5_2',\n",
    "\n",
    "'10binm1_0','10binx1_0', '10binm2_0','10binx2_0', '10binm3_0','10binx3_0', '10binm4_0','10binx4_0', '10binm5_0','10binx5_0',\n",
    "'10binm6_0','10binx6_0', '10binm7_0','10binx7_0', '10binm8_0','10binx8_0', '10binm9_0','10binx9_0', '10binm10_0','10binx10_0',\n",
    "\n",
    "'10binm1_1','10binx1_1', '10binm2_1','10binx2_1', '10binm3_1','10binx3_1', '10binm4_1','10binx4_1', '10binm5_1','10binx5_1',\n",
    "'10binm6_1','10binx6_1', '10binm7_1','10binx7_1', '10binm8_1','10binx8_1', '10binm9_1','10binx9_1', '10binm10_1','10binx10_1',\n",
    "\n",
    "'10binm1_2','10binx1_2', '10binm2_2','10binx2_2', '10binm3_2','10binx3_2', '10binm4_2','10binx4_2', '10binm5_2','10binx5_2',\n",
    "'10binm6_2','10binx6_2', '10binm7_2','10binx7_2', '10binm8_2','10binx8_2', '10binm9_2','10binx9_2', '10binm10_2','10binx10_2',\n",
    "\n",
    "'Rbinm1_0','Rbinm1_1','Rbinm1_2',\n",
    "'Rbinm2_0','Rbinm2_1','Rbinm2_2',\n",
    "'Rbinm3_0','Rbinm3_1','Rbinm3_2',\n",
    "'Rbinx1_0','Rbinx1_1','Rbinx1_2',\n",
    "'Rbinx2_0','Rbinx2_1','Rbinx2_2',\n",
    "'Rbinx3_0','Rbinx3_1','Rbinx3_2',\n",
    "'Nbinm1', 'Nbinm2', 'Nbinm3', 'Nbinx1', 'Nbinx2', 'Nbinx3',\n",
    "'Abinm1', 'Abinm2', 'Abinm3',\n",
    "'Abinx1', 'Abinx2', 'Abinx3',\n",
    "'Xbinm1', 'Xbinm2', 'Xbinm3',\n",
    "'Xbinx1', 'Xbinx2', 'Xbinx3'\n",
    " ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES USED: \n",
      " ['hrange' 'hmax' 'imax_0' 'imin_0' 'imean_0' 'isk_0' 'ikut_0' 'ip90_0'\n",
      " 'imax_1' 'imin_1' 'imean_1' 'isk_1' 'ikut_1' 'ip90_1' 'imax_2' 'imin_2'\n",
      " 'imean_2' 'isk_2' 'ikut_2' 'ip90_2']\n",
      "20  features\n"
     ]
    }
   ],
   "source": [
    "feats_to_use = ['i_p90', 'i_max', 'i_mean', 'i_sk','i_kut', 'i_min', 'h_range', 'h_max']\n",
    "\n",
    "#'h', 'H', 'p', 'C', 'D'\n",
    "\n",
    "feats = get_used_feats_names(feats_frame_columns=feats_cols, features_list=feats_to_use)\n",
    "\n",
    "columns_to_drop = [\n",
    "                    'V_min', 'V_median', 'V_sk', 'V_p90',\n",
    "                    'Abinm1', 'Abinx1',\n",
    "                    'Abinm2', 'Abinx2',\n",
    "                    'Xbinm1', 'Xbinx1',\n",
    "                    'Xbinm2', 'Xbinx2',\n",
    "                    'ibinm1_0','ibinm1_1','ibinm1_2',\n",
    "                    'ibinm2_0','ibinm2_1','ibinm2_2',\n",
    "                    'ibinm3_0','ibinm3_1','ibinm3_2',\n",
    "                    'ibinx1_0','ibinx1_1','ibinx1_2',\n",
    "                    'ibinx2_0','ibinx2_1','ibinx2_2',\n",
    "                    'ibinx3_0','ibinx3_1','ibinx3_2',\n",
    "                    ]\n",
    "columns_to_drop.extend([])\n",
    "feats = feats[~np.isin(feats, columns_to_drop)]\n",
    "\n",
    "print('FEATURES USED: \\n', feats)\n",
    "print(len(feats), ' features')\n",
    "\n",
    "X_train_sub = X_train[feats]\n",
    "X_val_sub = X_val[feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(eval_metric='mlogloss', max_depth=7, n_estimators=101, learning_rate=0.05, subsample=0.8)\n",
    "rf =  RandomForestClassifier(max_depth=14, n_estimators=101, class_weight='balanced')\n",
    "\n",
    "# RF: {'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 301}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8450704225352113\n",
      "0.8497652582159625\n",
      "0.8450704225352113\n",
      "0.8403755868544601\n",
      "0.8356807511737089\n",
      "0.8309859154929577\n",
      "0.8450704225352113\n",
      "0.8403755868544601\n",
      "0.8544600938967136\n",
      "0.8450704225352113\n",
      "0.8497652582159625\n",
      "0.8591549295774648\n",
      "0.8497652582159625\n",
      "0.8450704225352113\n",
      "0.8450704225352113\n",
      "0.8450704225352113\n",
      "0.8356807511737089\n",
      "0.8544600938967136\n",
      "0.8450704225352113\n",
      "0.8497652582159625\n",
      "0.8403755868544601\n",
      "0.8450704225352113\n",
      "0.8356807511737089\n",
      "0.8450704225352113\n",
      "0.8497652582159625\n",
      "0.8262910798122066\n",
      "0.8450704225352113\n",
      "0.8403755868544601\n",
      "0.8450704225352113\n",
      "0.8497652582159625\n",
      "0.8356807511737089\n",
      "0.8262910798122066\n",
      "0.8309859154929577\n",
      "0.8262910798122066\n",
      "0.8450704225352113\n",
      "0.8309859154929577\n",
      "0.8403755868544601\n",
      "0.8450704225352113\n",
      "0.8356807511737089\n",
      "0.8450704225352113\n",
      "0.8450704225352113\n",
      "0.8450704225352113\n",
      "0.8450704225352113\n",
      "0.8497652582159625\n",
      "0.8497652582159625\n",
      "0.8309859154929577\n",
      "0.8544600938967136\n",
      "0.8497652582159625\n",
      "0.8403755868544601\n",
      "0.8450704225352113\n",
      "0.8497652582159625\n",
      "0.8591549295774648\n",
      "0.8262910798122066\n",
      "0.8403755868544601\n",
      "0.8591549295774648\n",
      "0.8450704225352113\n",
      "0.8309859154929577\n",
      "0.8215962441314554\n",
      "0.8356807511737089\n",
      "0.8450704225352113\n",
      "0.8450704225352113\n",
      "0.8309859154929577\n",
      "0.8262910798122066\n",
      "0.8356807511737089\n",
      "0.8544600938967136\n",
      "0.8262910798122066\n",
      "0.8309859154929577\n",
      "0.8403755868544601\n",
      "0.8262910798122066\n",
      "0.8309859154929577\n",
      "0.8403755868544601\n",
      "0.8497652582159625\n",
      "0.8309859154929577\n",
      "0.8309859154929577\n",
      "0.8169014084507042\n",
      "0.8591549295774648\n",
      "0.8356807511737089\n",
      "0.8356807511737089\n",
      "0.8215962441314554\n",
      "0.8403755868544601\n",
      "0.8215962441314554\n",
      "0.8497652582159625\n",
      "0.8309859154929577\n",
      "0.8403755868544601\n",
      "0.8403755868544601\n",
      "0.8215962441314554\n",
      "0.8544600938967136\n",
      "0.8450704225352113\n",
      "0.8403755868544601\n",
      "0.8356807511737089\n",
      "0.8497652582159625\n",
      "0.8356807511737089\n",
      "0.8450704225352113\n",
      "0.8356807511737089\n",
      "0.8450704225352113\n",
      "0.8403755868544601\n",
      "0.8450704225352113\n",
      "0.8403755868544601\n",
      "0.8403755868544601\n",
      "0.8403755868544601\n",
      "0.8356807511737089\n",
      "0.8497652582159625\n",
      "0.8309859154929577\n",
      "0.8403755868544601\n",
      "0.8403755868544601\n",
      "0.8450704225352113\n",
      "0.8309859154929577\n",
      "0.8450704225352113\n",
      "0.8403755868544601\n",
      "0.8403755868544601\n",
      "0.8403755868544601\n",
      "0.8309859154929577\n",
      "0.8309859154929577\n",
      "0.8309859154929577\n",
      "0.8450704225352113\n",
      "0.8497652582159625\n",
      "0.8403755868544601\n",
      "0.8403755868544601\n",
      "0.8591549295774648\n",
      "0.8356807511737089\n",
      "0.8497652582159625\n",
      "0.8450704225352113\n",
      "0.8544600938967136\n",
      "0.8262910798122066\n",
      "0.8450704225352113\n",
      "0.8262910798122066\n",
      "0.8309859154929577\n",
      "0.8450704225352113\n",
      "0.8450704225352113\n",
      "0.8356807511737089\n",
      "0.8403755868544601\n",
      "0.8497652582159625\n",
      "0.8403755868544601\n",
      "0.8450704225352113\n",
      "0.8403755868544601\n",
      "0.8403755868544601\n",
      "0.8450704225352113\n",
      "0.8356807511737089\n",
      "0.8403755868544601\n",
      "0.8356807511737089\n",
      "0.8403755868544601\n",
      "0.8497652582159625\n",
      "0.8356807511737089\n",
      "0.8356807511737089\n",
      "0.8309859154929577\n",
      "0.8356807511737089\n",
      "0.8497652582159625\n",
      "0.8450704225352113\n",
      "0.8685446009389671\n",
      "\n",
      "JACKPOT\n",
      "Validation Accuracy: 0.869\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 50   1   9]\n",
      " [  3  17  10]\n",
      " [  2   3 118]]\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    clf = XGBClassifier(eval_metric='mlogloss', n_estimators=51, learning_rate=0.05, max_depth=14, subsample=0.7, random_state=epoch)\n",
    "    clf.fit(X_train_sub, y_train)\n",
    "    predictions = clf.predict(X_val_sub)\n",
    "    accuracy = accuracy_score(y_val, predictions)\n",
    "    print(accuracy)\n",
    "\n",
    "    if accuracy>0.865:\n",
    "        print('')\n",
    "        print('JACKPOT')\n",
    "        print(f'Validation Accuracy: {accuracy:.3f}')\n",
    "\n",
    "        cm = confusion_matrix(y_val, predictions)\n",
    "        print(\"\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID  Actual Species  Predicted Species\n",
      "147   1408               0                  2\n",
      "160   3513               1                  2\n",
      "161   3545               1                  2\n",
      "7     4404               0                  2\n",
      "8     5306               0                  2\n",
      "167   5530               0                  2\n",
      "10    5534               1                  0\n",
      "173   7985               2                  1\n",
      "178   8688               2                  0\n",
      "194  11406               0                  1\n",
      "31   13944               0                  2\n",
      "32   13968               2                  1\n",
      "35   14351               2                  0\n",
      "38   14753               0                  2\n",
      "39   14762               0                  2\n",
      "43   15110               1                  2\n",
      "44   15280               1                  2\n",
      "65   17108               0                  2\n",
      "78   18881               2                  1\n",
      "90   20338               0                  2\n",
      "92   20480               1                  2\n",
      "98   20751               1                  2\n",
      "103  21104               1                  2\n",
      "106  21424               1                  2\n",
      "111  21716               1                  0\n",
      "114  22207               1                  2\n",
      "118  22772               1                  2\n",
      "212  23407               1                  0\n"
     ]
    }
   ],
   "source": [
    "df_predictions = pd.DataFrame({\n",
    "    'ID': val_labels, \n",
    "    'Actual Species': y_val,\n",
    "    'Predicted Species': predictions\n",
    "})\n",
    "\n",
    "# Filter the dataframe to find where predictions are incorrect\n",
    "incorrect_preds = df_predictions[df_predictions['Actual Species'] != df_predictions['Predicted Species']]\n",
    "incorrect_preds_sorted = incorrect_preds.sort_values(by='ID')\n",
    "\n",
    "print(incorrect_preds_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATION OF XGBOOST AND RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.822\n",
      "Validation Accuracy: 0.850\n",
      "Validation Accuracy: 0.822\n",
      "Validation Accuracy: 0.822\n",
      "Validation Accuracy: 0.836\n",
      "Validation Accuracy: 0.840\n",
      "Validation Accuracy: 0.822\n",
      "Validation Accuracy: 0.822\n",
      "Validation Accuracy: 0.831\n",
      "Validation Accuracy: 0.826\n",
      "Validation Accuracy: 0.840\n",
      "Validation Accuracy: 0.845\n",
      "Validation Accuracy: 0.822\n",
      "Validation Accuracy: 0.836\n",
      "Validation Accuracy: 0.840\n",
      "Validation Accuracy: 0.826\n",
      "Validation Accuracy: 0.850\n",
      "Validation Accuracy: 0.831\n",
      "Validation Accuracy: 0.850\n",
      "Validation Accuracy: 0.840\n",
      "Validation Accuracy: 0.845\n",
      "Validation Accuracy: 0.826\n",
      "Validation Accuracy: 0.831\n",
      "Validation Accuracy: 0.826\n",
      "Validation Accuracy: 0.850\n",
      "Validation Accuracy: 0.831\n",
      "Validation Accuracy: 0.836\n",
      "Validation Accuracy: 0.854\n",
      "Validation Accuracy: 0.840\n",
      "Validation Accuracy: 0.840\n",
      "Validation Accuracy: 0.831\n",
      "Validation Accuracy: 0.836\n",
      "Validation Accuracy: 0.836\n",
      "Validation Accuracy: 0.826\n",
      "Validation Accuracy: 0.840\n",
      "Validation Accuracy: 0.840\n",
      "Validation Accuracy: 0.822\n",
      "Validation Accuracy: 0.840\n",
      "Validation Accuracy: 0.845\n",
      "Validation Accuracy: 0.836\n",
      "Validation Accuracy: 0.836\n",
      "Validation Accuracy: 0.840\n",
      "Validation Accuracy: 0.840\n",
      "Validation Accuracy: 0.836\n",
      "Validation Accuracy: 0.831\n",
      "Validation Accuracy: 0.845\n",
      "Validation Accuracy: 0.831\n",
      "Validation Accuracy: 0.840\n",
      "Validation Accuracy: 0.836\n",
      "Validation Accuracy: 0.836\n",
      "\n",
      "Best accuracy: 0.854\n",
      "Avg accuracy: 0.835\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "avg_acc = 0\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=101, random_state=epoch)\n",
    "    # clf = XGBClassifier(eval_metric='mlogloss', n_estimators=101, learning_rate=0.05, max_depth=14, subsample=0.7, random_state=epoch)\n",
    "    clf.fit(X_train_sub, y_train)\n",
    "\n",
    "    predictions = clf.predict(X_val_sub)\n",
    "    accuracy = accuracy_score(y_val, predictions)\n",
    "\n",
    "    avg_acc+=accuracy\n",
    "\n",
    "    if accuracy>best_acc:\n",
    "        best_acc = accuracy\n",
    "    print(f'Validation Accuracy: {accuracy:.3f}')\n",
    "\n",
    "avg_acc/=epochs\n",
    "print(\"\")\n",
    "print(f'Best accuracy: {best_acc:.3f}')\n",
    "print(f'Avg accuracy: {avg_acc:.3f}')\n",
    "\n",
    "\n",
    "## Best xgboost: 85.9%\n",
    "## Best RF: 85.4%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8450704225352113\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=201)\n",
    "rf.fit(X_train_sub, y_train)\n",
    "\n",
    "rf_predictions = rf.predict(X_val_sub)\n",
    "rf_accuracy = accuracy_score(y_val, rf_predictions)\n",
    "print(f'Validation Accuracy: {rf_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "Best parameters found:  {'bootstrap': False, 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "Best validation accuracy:  0.8004694835680751\n",
      "Improved Validation Accuracy: 0.8356807511737089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb = XGBClassifier(eval_metric='logloss')\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# candidate hyperparameters\n",
    "param_grid_xgb = {\n",
    "    'max_depth': [3, 5, 9],\n",
    "    'n_estimators': [100,200],\n",
    "    'learning_rate': [0.05],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10], \n",
    "    'min_samples_leaf': [1, 2, 4],  \n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(X_train_sub, y_train)\n",
    "\n",
    "# Best parameters and best accuracy\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best validation accuracy: \", grid_search.best_score_)\n",
    "\n",
    "# Use best estimator to make predictions\n",
    "best_estimator = grid_search.best_estimator_\n",
    "predictions = best_estimator.predict(X_val_sub)\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "print(f'Improved Validation Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SimpleView",
   "language": "python",
   "name": "simpleview"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
